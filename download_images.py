import requests
from bs4 import BeautifulSoup
import os  # ç”¨æ¥ç®¡ç†æ–‡ä»¶å¤¹

print("ğŸš€ å›¾ç‰‡ä¸‹è½½å™¨å¯åŠ¨...")

# 1. åˆ›å»ºä¸€ä¸ªæ–‡ä»¶å¤¹ä¸“é—¨å­˜å›¾ç‰‡
folder_name = "Book_Covers"
if not os.path.exists(folder_name):
    os.makedirs(folder_name)
    print(f"âœ… å·²åˆ›å»ºæ–‡ä»¶å¤¹: {folder_name}")

# 2. è®¿é—®ç½‘ç«™
url = "http://books.toscrape.com/"
response = requests.get(url)
soup = BeautifulSoup(response.text, "html.parser")

# 3. æ‰¾åˆ°æ‰€æœ‰ä¹¦çš„å°é¢å›¾ç‰‡
# åœ¨ HTML é‡Œï¼Œå›¾ç‰‡æ˜¯ <img> æ ‡ç­¾ï¼Œå®ƒçš„ class æ˜¯ "thumbnail"
images = soup.find_all("img", class_="thumbnail")

print(f"ğŸ” æ‰¾åˆ°äº† {len(images)} å¼ å›¾ç‰‡ï¼Œå¼€å§‹ä¸‹è½½...")

# 4. å¾ªç¯ä¸‹è½½æ¯ä¸€å¼ 
count = 1
for img in images:
    # è·å–å›¾ç‰‡çš„ç›¸å¯¹è·¯å¾„ (ä¾‹å¦‚: media/cache/...)
    img_src = img['src']
    
    # æ‹¼æ¥æˆå®Œæ•´çš„ç½‘å€
    # åŸç½‘ç«™çš„ src æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œæˆ‘ä»¬éœ€è¦æŠŠå®ƒæ‹¼åœ¨ä¸»åŸŸååé¢
    full_img_url = url + img_src
    
    print(f"â¬‡ï¸ æ­£åœ¨ä¸‹è½½ç¬¬ {count} å¼ : {full_img_url}")
    
    # ã€æ ¸å¿ƒçŸ¥è¯†ç‚¹ã€‘è¯·æ±‚å›¾ç‰‡æ•°æ® (æ³¨æ„æ˜¯ .content ä¹Ÿå°±æ˜¯äºŒè¿›åˆ¶æ•°æ®)
    img_data = requests.get(full_img_url).content
    
    # ã€æ ¸å¿ƒçŸ¥è¯†ç‚¹ã€‘ä¿å­˜æ–‡ä»¶
    # 'wb' çš„æ„æ€æ˜¯ Write Binary (å†™å…¥äºŒè¿›åˆ¶)ï¼Œä¸“é—¨ç”¨æ¥å­˜å›¾ç‰‡/è§†é¢‘
    with open(f"{folder_name}/cover_{count}.jpg", "wb") as f:
        f.write(img_data)
        
    count += 1

print("-" * 30)
print(f"ğŸ‰ ä»»åŠ¡å®Œæˆï¼è¯·å» [{folder_name}] æ–‡ä»¶å¤¹æŸ¥çœ‹æˆ˜åˆ©å“ã€‚")